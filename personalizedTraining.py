import cv2
import os
import json
from kivy.app import App
from kivy.clock import Clock
from kivy.uix.boxlayout import BoxLayout
from kivy.uix.button import Button
from kivy.uix.label import Label

# DicionÃ¡rio de recomendaÃ§Ãµes
instruction_texts = {
    "abriraboca": "Por favor, abra a boca. ğŸ˜²",
    "sorrir": "Por favor, sorria. ğŸ˜",
    "mostraralingua": "Por favor, mostre a lÃ­ngua. ğŸ˜",
    "levantarassobrancelhas": "Por favor, levante as sobrancelhas.",
    "piscarosolhos": "Por favor, pisque um dos olhos. ğŸ˜‰"
}

# FunÃ§Ã£o para carregar preferÃªncias do usuÃ¡rio
def load_user_preferences():
    with open('user_preferences.json', 'r', encoding='utf-8') as file:
        return json.load(file)

class CaptureApp(App):
    def build(self):
        self.layout = BoxLayout(orientation='vertical')
        self.label = Label(text="Vamos realizar um treinamento personalizado para vocÃª,\n"
                                "para isso, siga as instruÃ§Ãµes que lhe forem passadas a seguir.",
                           font_size='20sp', halign='center', valign='middle')
        self.label.bind(size=self.label.setter('text_size'))
        self.start_button = Button(text="Iniciar", font_size='20sp')
        self.start_button.bind(on_press=self.start_capture)
        self.layout.add_widget(self.label)
        self.layout.add_widget(self.start_button)
        return self.layout

    def start_capture(self, instance):
        # Carregar preferÃªncias do usuÃ¡rio
        self.preferences = load_user_preferences()
        # Coletar as preferÃªncias em uma lista
        self.gestures = [
            self.preferences["BotÃ£o Direito"],
            self.preferences["BotÃ£o Esquerdo"],
            self.preferences["Pressionar BotÃ£o Esquerdo"]
        ]

        # Iniciar o processo de captura
        self.current_gesture_index = 0
        self.capture_next_gesture()

    def capture_next_gesture(self):
        if self.current_gesture_index < len(self.gestures):
            gesture = self.gestures[self.current_gesture_index]
            self.label.text = instruction_texts[gesture.lower()] + "\nPreparando para capturar em 5 segundos..."
            # Agendar a captura de imagens apÃ³s 5 segundos
            Clock.schedule_once(lambda dt: self.capture_faces(gesture), 5)
            self.current_gesture_index += 1
        else:
            print("Captura concluÃ­da.")
            self.stop()  # Finaliza o aplicativo

    def capture_faces(self, subfolder_name):
        # Crie o diretÃ³rio da subpasta dentro de 'dataset', se nÃ£o existir
        dataset_dir = os.path.join('dataset', subfolder_name)
        if not os.path.exists(dataset_dir):
            os.makedirs(dataset_dir)

        # Inicialize a webcam
        cam = cv2.VideoCapture(0)

        # Espelhar a cÃ¢mera
        cam.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

        print(f"Capturando faces para a subpasta '{subfolder_name}'. Olhe para a cÃ¢mera e espere...")
        capturas = len(os.listdir(dataset_dir))
        count = 0
        while count < 100:
            ret, img = cam.read()

            # Espelha a imagem horizontalmente para uma visualizaÃ§Ã£o mais natural
            img = cv2.flip(img, 1)

            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            faces = cv2.CascadeClassifier('haarcascade_frontalface_default.xml').detectMultiScale(gray, 1.3, 5)

            for (x, y, w, h) in faces:
                count += 1
                # Salve a imagem capturada no dataset/subpasta
                capturas += 1
                cv2.imwrite(f"{dataset_dir}/User.{capturas}.jpg", gray)
                cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)

            cv2.imshow('image', img)

            # Interrompe o processo se capturar 30 fotos ou se o usuÃ¡rio pressionar 'q'
            if cv2.waitKey(100) & 0xFF == ord('q'):
                break

        cam.release()
        cv2.destroyAllWindows()

        # Chama o prÃ³ximo gesto apÃ³s capturar as fotos
        # Certifique-se de que o prÃ³ximo gesto sÃ³ Ã© chamado apÃ³s a captura estar completa
        Clock.schedule_once(lambda dt: self.capture_next_gesture(), 1)  # Atrasar ligeiramente antes de chamar o prÃ³ximo gesto


# Chama a funÃ§Ã£o para iniciar a aplicaÃ§Ã£o
if __name__ == '__main__':
    CaptureApp().run()
